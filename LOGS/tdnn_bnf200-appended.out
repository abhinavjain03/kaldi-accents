feat-to-dim scp:data/cv_train_nz_mfcc_bnf_appended_sp/feats.scp - 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_bnf200-appended/configs/network.xconfig --config-dir exp/nnet3/tdnn_bnf200-appended/configs/
nnet3-init exp/nnet3/tdnn_bnf200-appended/configs//ref.config exp/nnet3/tdnn_bnf200-appended/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_bnf200-appended/configs//ref.raw
nnet3-info exp/nnet3/tdnn_bnf200-appended/configs//ref.raw 
nnet3-init exp/nnet3/tdnn_bnf200-appended/configs//ref.config exp/nnet3/tdnn_bnf200-appended/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_bnf200-appended/configs//ref.raw
nnet3-info exp/nnet3/tdnn_bnf200-appended/configs//ref.raw 
./run_with_accent_embedding.sh: calling get_egs.sh for generating examples with alignments as output
steps/nnet3/get_egs.sh --cmvn-opts --norm-means=false --norm-vars=false --left-context 16 --right-context 12 --num-utts-subset 300 --nj 20 --samples-per-iter 50000 --cmd run.pl --frames-per-eg 8 data/cv_train_nz_mfcc_bnf_appended_sp exp/tri4_cv_train_nz_sp_ali exp/nnet3/tdnn_bnf200-appended/egs
File data/cv_train_nz_mfcc_bnf_appended_sp/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: feature type is raw
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
steps/nnet3/get_egs.sh: creating 6 archives, each with 42120 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (16,12)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_bnf200-appended/egs/ali.ark,exp/nnet3/tdnn_bnf200-appended/egs/ali.scp 
LOG (copy-int-vector[5.2.204~1-08848]:main():copy-int-vector.cc:83) Copied 92660 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments and transforms
steps/nnet3/get_egs.sh: Finished preparing training examples
2018-02-19 00:10:51,959 [steps/nnet3/train_dnn.py:35 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 2 --trainer.optimization.num-jobs-initial 3 --trainer.optimization.num-jobs-final 6 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir exp/nnet3/tdnn_bnf200-appended/egs --cleanup.preserve-model-interval 20 --use-gpu true --ali-dir exp/tri4_cv_train_nz_sp_ali --lang data/lang --feat-dir=data/cv_train_nz_mfcc_bnf_appended_sp --reporting.email= --dir exp/nnet3/tdnn_bnf200-appended
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '2', '--trainer.optimization.num-jobs-initial', '3', '--trainer.optimization.num-jobs-final', '6', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', 'exp/nnet3/tdnn_bnf200-appended/egs', '--cleanup.preserve-model-interval', '20', '--use-gpu', 'true', '--ali-dir', 'exp/tri4_cv_train_nz_sp_ali', '--lang', 'data/lang', '--feat-dir=data/cv_train_nz_mfcc_bnf_appended_sp', '--reporting.email=', '--dir', 'exp/nnet3/tdnn_bnf200-appended']
2018-02-19 00:10:51,980 [steps/nnet3/train_dnn.py:163 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri4_cv_train_nz_sp_ali',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_bnf200-appended',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': 'exp/nnet3/tdnn_bnf200-appended/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/cv_train_nz_mfcc_bnf_appended_sp',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 6,
 'num_jobs_initial': 3,
 'online_ivector_dir': None,
 'preserve_model_interval': 20,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'transform_dir': 'exp/tri4_cv_train_nz_sp_ali',
 'use_gpu': True}
2018-02-19 00:10:52,620 [steps/libs/nnet3/train/common.py:440 - verify_egs_dir - WARNING ] The ivector ids are not used. It's your responsibility to make sure the ivector extractor has been used consistently
2018-02-19 00:10:52,621 [steps/nnet3/train_dnn.py:263 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2018-02-19 00:10:59,507 [steps/nnet3/train_dnn.py:270 - train - INFO ] Preparing the initial acoustic model.
2018-02-19 00:11:11,463 [steps/nnet3/train_dnn.py:295 - train - INFO ] Training will run for 2.0 epochs = 21 iterations
2018-02-19 00:11:11,464 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 0)
2018-02-19 00:11:11,614 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.0051.
2018-02-19 00:28:43,717 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 1)
2018-02-19 00:28:43,725 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 1, learning rate is 0.00474591740874.
2018-02-19 00:34:19,607 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 2)
2018-02-19 00:34:19,615 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 2, learning rate is 0.00441641804914.
2018-02-19 00:39:07,941 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 3)
2018-02-19 00:39:07,948 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 3, learning rate is 0.00410979515758.
2018-02-19 00:44:59,252 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 4)
2018-02-19 00:44:59,257 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 4, learning rate is 0.00509928062346.
2018-02-19 00:51:07,040 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 5)
2018-02-19 00:51:07,049 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 5, learning rate is 0.00463278606959.
2018-02-19 00:57:43,214 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 6)
2018-02-19 00:57:43,223 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 6, learning rate is 0.00420896756846.
2018-02-19 01:03:49,700 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 7)
2018-02-19 01:03:49,709 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 7, learning rate is 0.00382392101129.
2018-02-19 01:09:20,168 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 8)
2018-02-19 01:09:20,183 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 8, learning rate is 0.00347409944666.
2018-02-19 01:14:55,912 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 9)
2018-02-19 01:14:55,923 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 9, learning rate is 0.00315628040686.
2018-02-19 01:19:52,396 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 10)
2018-02-19 01:19:52,404 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 10, learning rate is 0.00286753622331.
2018-02-19 01:24:36,866 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 11)
2018-02-19 01:24:36,876 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 11, learning rate is 0.00325650882212.
2018-02-19 01:30:13,053 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 12)
2018-02-19 01:30:13,072 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 12, learning rate is 0.0028884770796.
2018-02-19 01:35:03,112 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 13)
2018-02-19 01:35:03,118 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 13, learning rate is 0.0025620381504.
2018-02-19 01:39:52,345 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 14)
2018-02-19 01:39:52,354 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 14, learning rate is 0.00227249145594.
2018-02-19 01:44:43,971 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 15)
2018-02-19 01:44:43,980 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 15, learning rate is 0.00201566764981.
2018-02-19 01:52:17,217 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 16)
2018-02-19 01:52:17,224 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 16, learning rate is 0.00178786858092.
2018-02-19 01:59:52,786 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 17)
2018-02-19 01:59:52,795 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 17, learning rate is 0.00158581404179.
2018-02-19 02:07:29,044 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 18)
2018-02-19 02:07:29,054 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 18, learning rate is 0.00168791344194.
2018-02-19 02:16:01,751 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 19)
2018-02-19 02:16:01,775 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 19, learning rate is 0.00146167282164.
2018-02-19 02:24:31,560 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 20)
2018-02-19 02:24:31,568 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 20, learning rate is 0.00102.
2018-02-19 02:35:19,921 [steps/nnet3/train_dnn.py:361 - train - INFO ] Doing final combination to produce final.mdl
2018-02-19 02:35:19,921 [steps/libs/nnet3/train/frame_level_objf/common.py:466 - combine_models - INFO ] Combining set([12, 13, 14, 15, 16, 17, 18, 19, 20, 21]) models.
2018-02-19 02:38:54,094 [steps/nnet3/train_dnn.py:370 - train - INFO ] Getting average posterior for purposes of adjusting the priors.
2018-02-19 02:45:18,514 [steps/nnet3/train_dnn.py:381 - train - INFO ] Re-adjusting priors based on computed posteriors
2018-02-19 02:45:19,036 [steps/nnet3/train_dnn.py:391 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_bnf200-appended
exp/nnet3/tdnn_bnf200-appended: num-iters=21 nj=3..6 num-params=22.1M dim=240->9054 combine=-1.23->-1.11 loglike:train/valid[13,20,combined]=(-1.35,-1.10,-1.07/-1.58,-1.44,-1.42) accuracy:train/valid[13,20,combined]=(0.62,0.67,0.68/0.58,0.61,0.61)
steps/nnet3/make_bottleneck_features.sh --nj 20 --use-gpu true --cmd run.pl tdnn_bn.renorm data/cv_test_onlyindian_hires data/cv_test_onlyindian_bnf /exp/abhinav/accent_recognizer_exp/nnet3/tdnn_1024nodes_200bnlayer exp/make_bnf/cv_test_onlyindian exp/make_bnf
steps/nnet3/make_bottleneck_features.sh: Generating bottleneck features using /exp/abhinav/accent_recognizer_exp/nnet3/tdnn_1024nodes_200bnlayer/final.raw model as output of 
    component-node with name tdnn_bn.renorm.
steps/nnet3/make_bottleneck_features.sh: computing CMVN stats.
steps/compute_cmvn_stats.sh data/cv_test_onlyindian_bnf
Succeeded creating CMVN stats for cv_test_onlyindian_bnf
steps/nnet3/make_bottleneck_features.sh: done making BNF feats.scp.
steps/nnet3/make_bottleneck_features.sh --nj 20 --use-gpu true --cmd run.pl tdnn_bn.renorm data/cv_dev_nz_hires data/cv_dev_nz_bnf /exp/abhinav/accent_recognizer_exp/nnet3/tdnn_1024nodes_200bnlayer exp/make_bnf/cv_dev_nz exp/make_bnf
steps/nnet3/make_bottleneck_features.sh: Generating bottleneck features using /exp/abhinav/accent_recognizer_exp/nnet3/tdnn_1024nodes_200bnlayer/final.raw model as output of 
    component-node with name tdnn_bn.renorm.
steps/nnet3/make_bottleneck_features.sh: computing CMVN stats.
steps/compute_cmvn_stats.sh data/cv_dev_nz_bnf
Succeeded creating CMVN stats for cv_dev_nz_bnf
steps/nnet3/make_bottleneck_features.sh: done making BNF feats.scp.
steps/nnet3/make_bottleneck_features.sh --nj 20 --use-gpu true --cmd run.pl tdnn_bn.renorm data/cv_test_onlynz_hires data/cv_test_onlynz_bnf /exp/abhinav/accent_recognizer_exp/nnet3/tdnn_1024nodes_200bnlayer exp/make_bnf/cv_test_onlynz exp/make_bnf
steps/nnet3/make_bottleneck_features.sh: Generating bottleneck features using /exp/abhinav/accent_recognizer_exp/nnet3/tdnn_1024nodes_200bnlayer/final.raw model as output of 
    component-node with name tdnn_bn.renorm.
steps/nnet3/make_bottleneck_features.sh: computing CMVN stats.
steps/compute_cmvn_stats.sh data/cv_test_onlynz_bnf
Succeeded creating CMVN stats for cv_test_onlynz_bnf
steps/nnet3/make_bottleneck_features.sh: done making BNF feats.scp.
steps/append_feats.sh --cmd run.pl --nj 20 data/cv_test_onlyindian_bnf data/cv_test_onlyindian_hires data/cv_test_onlyindian_mfcc_bnf_appended exp/append_hires_mfcc_bnf/cv_test_onlyindian exp/append_mfcc_bnf
Succeeded pasting features for cv_test_onlyindian_mfcc_bnf_appended into data/cv_test_onlyindian_mfcc_bnf_appended
steps/compute_cmvn_stats.sh data/cv_test_onlyindian_mfcc_bnf_appended exp/make_cmvn_mfcc_bnf exp/append_mfcc_bnf
Succeeded creating CMVN stats for cv_test_onlyindian_mfcc_bnf_appended
steps/append_feats.sh --cmd run.pl --nj 20 data/cv_dev_nz_bnf data/cv_dev_nz_hires data/cv_dev_nz_mfcc_bnf_appended exp/append_hires_mfcc_bnf/cv_dev_nz exp/append_mfcc_bnf
Succeeded pasting features for cv_dev_nz_mfcc_bnf_appended into data/cv_dev_nz_mfcc_bnf_appended
steps/compute_cmvn_stats.sh data/cv_dev_nz_mfcc_bnf_appended exp/make_cmvn_mfcc_bnf exp/append_mfcc_bnf
Succeeded creating CMVN stats for cv_dev_nz_mfcc_bnf_appended
steps/append_feats.sh --cmd run.pl --nj 20 data/cv_test_onlynz_bnf data/cv_test_onlynz_hires data/cv_test_onlynz_mfcc_bnf_appended exp/append_hires_mfcc_bnf/cv_test_onlynz exp/append_mfcc_bnf
Succeeded pasting features for cv_test_onlynz_mfcc_bnf_appended into data/cv_test_onlynz_mfcc_bnf_appended
steps/compute_cmvn_stats.sh data/cv_test_onlynz_mfcc_bnf_appended exp/make_cmvn_mfcc_bnf exp/append_mfcc_bnf
Succeeded creating CMVN stats for cv_test_onlynz_mfcc_bnf_appended
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg data/cv_test_onlyindian_mfcc_bnf_appended exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlyindian_mfcc_bnf_appended
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/tri4/graph_sw1_tg exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlyindian_mfcc_bnf_appended
analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 76.404494382% of the time at utterance end.  This may not be optimal.
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlyindian_mfcc_bnf_appended/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,16,91) and mean=35.3
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlyindian_mfcc_bnf_appended/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/cv_test_onlyindian_mfcc_bnf_appended exp/tri4/graph_sw1_tg exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlyindian_mfcc_bnf_appended
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg data/cv_dev_nz_mfcc_bnf_appended exp/nnet3/tdnn_bnf200-appended/decode_cv_dev_nz_mfcc_bnf_appended
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/tri4/graph_sw1_tg exp/nnet3/tdnn_bnf200-appended/decode_cv_dev_nz_mfcc_bnf_appended
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3/tdnn_bnf200-appended/decode_cv_dev_nz_mfcc_bnf_appended/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,27) and mean=12.2
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3/tdnn_bnf200-appended/decode_cv_dev_nz_mfcc_bnf_appended/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/cv_dev_nz_mfcc_bnf_appended exp/tri4/graph_sw1_tg exp/nnet3/tdnn_bnf200-appended/decode_cv_dev_nz_mfcc_bnf_appended
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G exp/tri4/graph_sw1_tg data/cv_test_onlynz_mfcc_bnf_appended exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlynz_mfcc_bnf_appended
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/tri4/graph_sw1_tg exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlynz_mfcc_bnf_appended
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlynz_mfcc_bnf_appended/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,26) and mean=11.0
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlynz_mfcc_bnf_appended/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/cv_test_onlynz_mfcc_bnf_appended exp/tri4/graph_sw1_tg exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlynz_mfcc_bnf_appended
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
%WER 22.29 [ 2315 / 10386, 270 ins, 377 del, 1668 sub ] exp/nnet3/tdnn_bnf200-appended/decode_cv_dev_nz_mfcc_bnf_appended/wer_11_1.0
%WER 54.12 [ 440 / 813, 30 ins, 104 del, 306 sub ] exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlyindian_mfcc_bnf_appended/wer_17_1.0
%WER 23.44 [ 1193 / 5089, 141 ins, 136 del, 916 sub ] exp/nnet3/tdnn_bnf200-appended/decode_cv_test_onlynz_mfcc_bnf_appended/wer_10_1.0
