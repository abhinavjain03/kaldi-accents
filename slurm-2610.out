steps/nnet3/make_bottleneck_features.sh --nj 20 --use-gpu true --ivector-dir exp/nnet3/ivectors_cv_train_nz_sp --cmd run.pl acc_btn.renorm data/cv_train_nz_sp_hires data/cv_train_nz_sp_bnf /exp/minali/accents_multitask_exp/nnet3/multitask_accent_4sharedlayers_300bnf_0.5_0.5 exp/make_bnf/cv_train_nz_sp exp/make_bnf
steps/nnet3/make_bottleneck_features.sh: line 78: /exp/minali/accents_multitask_exp/nnet3/multitask_accent_4sharedlayers_300bnf_0.5_0.5/num_jobs: Permission denied
steps/nnet3/make_bottleneck_features.sh: Generating bottleneck features using /exp/minali/accents_multitask_exp/nnet3/multitask_accent_4sharedlayers_300bnf_0.5_0.5/final.raw model as output of 
    component-node with name acc_btn.renorm.
steps/nnet3/make_bottleneck_features.sh: computing CMVN stats.
steps/compute_cmvn_stats.sh data/cv_train_nz_sp_bnf
Succeeded creating CMVN stats for cv_train_nz_sp_bnf
steps/nnet3/make_bottleneck_features.sh: done making BNF feats.scp.
steps/append_feats.sh --cmd run.pl --nj 20 data/cv_train_nz_sp_bnf data/cv_train_nz_sp_hires data/cv_train_nz_mfcc_bnf_appended_sp exp/append_hires_mfcc_bnf/cv_train_nz_sp exp/append_mfcc_bnf
Succeeded pasting features for cv_train_nz_mfcc_bnf_appended_sp into data/cv_train_nz_mfcc_bnf_appended_sp
steps/compute_cmvn_stats.sh data/cv_train_nz_mfcc_bnf_appended_sp exp/make_cmvn_mfcc_bnf exp/append_mfcc_bnf
Succeeded creating CMVN stats for cv_train_nz_mfcc_bnf_appended_sp
feat-to-dim scp:data/cv_train_nz_mfcc_bnf_appended_sp/feats.scp - 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs/network.xconfig --config-dir exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs/
nnet3-init exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.config exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.raw
nnet3-info exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.raw 
nnet3-init exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.config exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.raw
nnet3-info exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/configs//ref.raw 
./run_with_accent_embedding_with_ivectors_min.sh: calling get_egs.sh for generating examples with alignments as output
steps/nnet3/get_egs.sh --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_cv_train_nz_sp --left-context 16 --right-context 12 --num-utts-subset 300 --nj 20 --samples-per-iter 400000 --cmd run.pl --frames-per-eg 8 data/cv_train_nz_mfcc_bnf_appended_sp exp/tri4_cv_train_nz_sp_ali exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs
File data/cv_train_nz_mfcc_bnf_appended_sp/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: feature type is raw
feat-to-dim scp:exp/nnet3/ivectors_cv_train_nz_sp/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
steps/nnet3/get_egs.sh: creating 12 archives, each with 387321 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (16,12)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/ali.ark,exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/ali.scp 
LOG (copy-int-vector[5.2.204~1-08848]:main():copy-int-vector.cc:83) Copied 92660 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments and transforms
steps/nnet3/get_egs.sh: Finished preparing training examples
2018-03-12 20:36:03,686 [steps/nnet3/train_dnn.py:35 - <module> - INFO ] Starting DNN trainer (train_dnn.py)
steps/nnet3/train_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 2 --trainer.optimization.num-jobs-initial 3 --trainer.optimization.num-jobs-final 9 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs --feat.online-ivector-dir exp/nnet3/ivectors_cv_train_nz_sp --cleanup.preserve-model-interval 20 --use-gpu true --ali-dir exp/tri4_cv_train_nz_sp_ali --lang data/lang --feat-dir=data/cv_train_nz_mfcc_bnf_appended_sp --reporting.email= --dir exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5
['steps/nnet3/train_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '2', '--trainer.optimization.num-jobs-initial', '3', '--trainer.optimization.num-jobs-final', '9', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', 'exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs', '--feat.online-ivector-dir', 'exp/nnet3/ivectors_cv_train_nz_sp', '--cleanup.preserve-model-interval', '20', '--use-gpu', 'true', '--ali-dir', 'exp/tri4_cv_train_nz_sp_ali', '--lang', 'data/lang', '--feat-dir=data/cv_train_nz_mfcc_bnf_appended_sp', '--reporting.email=', '--dir', 'exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5']
2018-03-12 20:36:03,745 [steps/nnet3/train_dnn.py:163 - train - INFO ] Arguments for the experiment
{'ali_dir': 'exp/tri4_cv_train_nz_sp_ali',
 'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': 'exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/cv_train_nz_mfcc_bnf_appended_sp',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'initial_effective_lrate': 0.0017,
 'lang': 'data/lang',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 9,
 'num_jobs_initial': 3,
 'online_ivector_dir': 'exp/nnet3/ivectors_cv_train_nz_sp',
 'preserve_model_interval': 20,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'transform_dir': 'exp/tri4_cv_train_nz_sp_ali',
 'use_gpu': True}
2018-03-12 20:36:04,170 [steps/nnet3/train_dnn.py:264 - train - INFO ] Computing initial vector for FixedScaleComponent before softmax, using priors^-0.25 and rescaling to average 1
2018-03-12 20:36:08,588 [steps/nnet3/train_dnn.py:271 - train - INFO ] Preparing the initial acoustic model.
2018-03-12 20:36:15,407 [steps/nnet3/train_dnn.py:296 - train - INFO ] Training will run for 2.0 epochs = 32 iterations
2018-03-12 20:36:15,407 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 0)
2018-03-12 20:36:15,509 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.0051.
2018-03-12 20:40:16,193 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 1)
2018-03-12 20:40:16,204 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 1, learning rate is 0.00491977426155.
2018-03-12 20:44:00,348 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 2)
2018-03-12 20:44:00,357 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 2, learning rate is 0.00474591740874.
2018-03-12 20:47:09,605 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 3)
2018-03-12 20:47:09,612 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 3, learning rate is 0.00610427250064.
2018-03-12 20:50:34,216 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 4)
2018-03-12 20:50:34,223 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 4, learning rate is 0.00581835987249.
2018-03-12 20:53:36,269 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 5)
2018-03-12 20:53:36,284 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 5, learning rate is 0.0055458388534.
2018-03-12 20:57:42,293 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 6)
2018-03-12 20:57:42,335 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 6, learning rate is 0.00528608220562.
2018-03-12 21:03:49,080 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 7)
2018-03-12 21:03:49,120 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 7, learning rate is 0.00503849207005.
2018-03-12 21:10:08,623 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 8)
2018-03-12 21:10:08,671 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 8, learning rate is 0.00600312323769.
2018-03-12 21:17:06,425 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 9)
2018-03-12 21:17:06,434 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 9, learning rate is 0.00565373687277.
2018-03-12 21:21:42,152 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 10)
2018-03-12 21:21:42,159 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 10, learning rate is 0.00532468506158.
2018-03-12 21:25:27,415 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 11)
2018-03-12 21:25:27,421 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 11, learning rate is 0.00501478431754.
2018-03-12 21:30:07,141 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 12)
2018-03-12 21:30:07,173 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 12, learning rate is 0.00472292003387.
2018-03-12 21:34:42,741 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 13)
2018-03-12 21:34:42,765 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 13, learning rate is 0.00444804247479.
2018-03-12 21:42:09,819 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 14)
2018-03-12 21:42:09,830 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 14, learning rate is 0.00502699559993.
2018-03-12 21:46:54,974 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 15)
2018-03-12 21:46:54,980 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 15, learning rate is 0.00467798155517.
2018-03-12 21:51:16,947 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 16)
2018-03-12 21:51:16,954 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 16, learning rate is 0.00435319884323.
2018-03-12 21:55:59,234 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 17)
2018-03-12 21:55:59,241 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 17, learning rate is 0.00405096513211.
2018-03-12 22:00:04,283 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 18)
2018-03-12 22:00:04,290 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 18, learning rate is 0.00376971489073.
2018-03-12 22:04:09,857 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 19)
2018-03-12 22:04:09,864 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 19, learning rate is 0.00409265649285.
2018-03-12 22:08:53,325 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 20)
2018-03-12 22:08:53,331 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 20, learning rate is 0.0037631104156.
2018-03-12 22:14:20,372 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 21)
2018-03-12 22:14:20,378 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 21, learning rate is 0.00346009982141.
2018-03-12 22:19:06,876 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 22)
2018-03-12 22:19:06,882 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 22, learning rate is 0.00318148803832.
2018-03-12 22:23:54,853 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 23)
2018-03-12 22:23:54,859 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 23, learning rate is 0.00292531044202.
2018-03-12 22:28:41,582 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 24)
2018-03-12 22:28:41,587 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 24, learning rate is 0.00307401211691.
2018-03-12 22:34:10,420 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 25)
2018-03-12 22:34:10,427 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 25, learning rate is 0.00279279403598.
2018-03-12 22:40:48,274 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 26)
2018-03-12 22:40:48,328 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 26, learning rate is 0.00253730246686.
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.8.log
2018-03-12 22:42:18,580 [steps/libs/common.py:231 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --mem 4G --gpu 1 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.8.log                     nnet3-train  --read-cache=exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/cache.26                       --print-interval=10                     --momentum=0.0                     --max-param-change=2.0                     --backstitch-training-scale=0.0                     --l2-regularize-factor=0.125                     --backstitch-training-interval=1                     --srand=26                      "nnet3-copy --learning-rate=0.00253730246686 --scale=1.0 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/26.mdl - |" "ark,bg:nnet3-copy-egs --frame=0              ark:exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/egs.4.ark ark:- |             nnet3-shuffle-egs --buffer-size=5000             --srand=26 ark:- ark:- |              nnet3-merge-egs --minibatch-size=512 ark:- ark:- |"                     exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/27.8.raw
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.4.log
2018-03-12 22:42:18,600 [steps/libs/common.py:231 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --mem 4G --gpu 1 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.4.log                     nnet3-train  --read-cache=exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/cache.26                       --print-interval=10                     --momentum=0.0                     --max-param-change=2.0                     --backstitch-training-scale=0.0                     --l2-regularize-factor=0.125                     --backstitch-training-interval=1                     --srand=26                      "nnet3-copy --learning-rate=0.00253730246686 --scale=1.0 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/26.mdl - |" "ark,bg:nnet3-copy-egs --frame=7              ark:exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/egs.12.ark ark:- |             nnet3-shuffle-egs --buffer-size=5000             --srand=26 ark:- ark:- |              nnet3-merge-egs --minibatch-size=512 ark:- ark:- |"                     exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/27.4.raw
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.7.log
2018-03-12 22:42:18,760 [steps/libs/common.py:231 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --mem 4G --gpu 1 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.7.log                     nnet3-train  --read-cache=exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/cache.26                       --print-interval=10                     --momentum=0.0                     --max-param-change=2.0                     --backstitch-training-scale=0.0                     --l2-regularize-factor=0.125                     --backstitch-training-interval=1                     --srand=26                      "nnet3-copy --learning-rate=0.00253730246686 --scale=1.0 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/26.mdl - |" "ark,bg:nnet3-copy-egs --frame=7              ark:exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/egs.3.ark ark:- |             nnet3-shuffle-egs --buffer-size=5000             --srand=26 ark:- ark:- |              nnet3-merge-egs --minibatch-size=512 ark:- ark:- |"                     exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/27.7.raw
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.6.log
2018-03-12 22:42:18,768 [steps/libs/common.py:231 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --mem 4G --gpu 1 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.6.log                     nnet3-train  --read-cache=exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/cache.26                       --print-interval=10                     --momentum=0.0                     --max-param-change=2.0                     --backstitch-training-scale=0.0                     --l2-regularize-factor=0.125                     --backstitch-training-interval=1                     --srand=26                      "nnet3-copy --learning-rate=0.00253730246686 --scale=1.0 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/26.mdl - |" "ark,bg:nnet3-copy-egs --frame=6              ark:exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/egs.2.ark ark:- |             nnet3-shuffle-egs --buffer-size=5000             --srand=26 ark:- ark:- |              nnet3-merge-egs --minibatch-size=512 ark:- ark:- |"                     exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/27.6.raw
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.1.log
2018-03-12 22:42:18,788 [steps/libs/common.py:231 - background_command_waiter - ERROR ] Command exited with status 1: run.pl --mem 4G --gpu 1 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.1.log                     nnet3-train  --read-cache=exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/cache.26 --write-cache=exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/cache.27                       --print-interval=10                     --momentum=0.0                     --max-param-change=2.0                     --backstitch-training-scale=0.0                     --l2-regularize-factor=0.125                     --backstitch-training-interval=1                     --srand=26                      "nnet3-copy --learning-rate=0.00253730246686 --scale=1.0 exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/26.mdl - |" "ark,bg:nnet3-copy-egs --frame=4              ark:exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/egs/egs.9.ark ark:- |             nnet3-shuffle-egs --buffer-size=5000             --srand=26 ark:- ark:- |              nnet3-merge-egs --minibatch-size=512 ark:- ark:- |"                     exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/27.1.raw
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.3.log
run.pl: job failed, log is in exp/nnet3/tdnn_bnf300_4sharedlayers_300bnf_0.5_0.5/log/train.26.2.log
